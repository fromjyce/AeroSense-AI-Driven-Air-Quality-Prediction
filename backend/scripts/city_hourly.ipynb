{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WR-gW4XOE0CS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e8qmbJ8zFGoA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('city_hour.csv')\n",
        "df['Datetime'] = pd.to_datetime(df['Datetime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OuNGD_igFJi6"
      },
      "outputs": [],
      "source": [
        "df['Month'] = df['Datetime'].dt.month\n",
        "df['Year'] = df['Datetime'].dt.year\n",
        "df['Hour'] = df['Datetime'].dt.hour\n",
        "df['Minute'] = df['Datetime'].dt.minute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n5LWbTVFLYB",
        "outputId": "eadb11b2-ac53-4316-c196-f626d3c2d4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 707875 entries, 0 to 707874\n",
            "Data columns (total 20 columns):\n",
            " #   Column      Non-Null Count   Dtype         \n",
            "---  ------      --------------   -----         \n",
            " 0   City        707875 non-null  object        \n",
            " 1   Datetime    707875 non-null  datetime64[ns]\n",
            " 2   PM2.5       562787 non-null  float64       \n",
            " 3   PM10        411138 non-null  float64       \n",
            " 4   NO          591243 non-null  float64       \n",
            " 5   NO2         590753 non-null  float64       \n",
            " 6   NOx         584651 non-null  float64       \n",
            " 7   NH3         435333 non-null  float64       \n",
            " 8   CO          621358 non-null  float64       \n",
            " 9   SO2         577502 non-null  float64       \n",
            " 10  O3          578667 non-null  float64       \n",
            " 11  Benzene     544229 non-null  float64       \n",
            " 12  Toluene     487268 non-null  float64       \n",
            " 13  Xylene      252046 non-null  float64       \n",
            " 14  AQI         578795 non-null  float64       \n",
            " 15  AQI_Bucket  578795 non-null  object        \n",
            " 16  Month       707875 non-null  int32         \n",
            " 17  Year        707875 non-null  int32         \n",
            " 18  Hour        707875 non-null  int32         \n",
            " 19  Minute      707875 non-null  int32         \n",
            "dtypes: datetime64[ns](1), float64(13), int32(4), object(2)\n",
            "memory usage: 97.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1hQdbx_FM8A",
        "outputId": "2075fdcf-cfd9-401c-f984-90c842a31937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "City               0\n",
            "Datetime           0\n",
            "PM2.5         145088\n",
            "PM10          296737\n",
            "NO            116632\n",
            "NO2           117122\n",
            "NOx           123224\n",
            "NH3           272542\n",
            "CO             86517\n",
            "SO2           130373\n",
            "O3            129208\n",
            "Benzene       163646\n",
            "Toluene       220607\n",
            "Xylene        455829\n",
            "AQI           129080\n",
            "AQI_Bucket    129080\n",
            "Month              0\n",
            "Year               0\n",
            "Hour               0\n",
            "Minute             0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count null values in each column\n",
        "null_count = df.isnull().sum()\n",
        "print(null_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_001VjduFQY6"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[ 'NH3', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique Cities: ['Ahmedabad' 'Aizawl' 'Amaravati' 'Amritsar' 'Bengaluru' 'Bhopal'\n",
            " 'Brajrajnagar' 'Chandigarh' 'Chennai' 'Coimbatore' 'Delhi' 'Ernakulam'\n",
            " 'Gurugram' 'Guwahati' 'Hyderabad' 'Jaipur' 'Jorapokhar' 'Kochi' 'Kolkata'\n",
            " 'Lucknow' 'Mumbai' 'Patna' 'Shillong' 'Talcher' 'Thiruvananthapuram'\n",
            " 'Visakhapatnam']\n"
          ]
        }
      ],
      "source": [
        "cities = df['City'].unique()\n",
        "print(\"Unique Cities:\", cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Too many rows removed for Mumbai. Retaining maximum allowed rows.\n",
            "                 City            Datetime  PM2.5   PM10    NO    NO2    NOx   \n",
            "0           Ahmedabad 2015-01-01 01:00:00    NaN    NaN  1.00  40.01  36.37  \\\n",
            "1           Ahmedabad 2015-01-01 02:00:00    NaN    NaN  0.02  27.75  19.73   \n",
            "2           Ahmedabad 2015-01-01 03:00:00    NaN    NaN  0.08  19.32  11.08   \n",
            "3           Ahmedabad 2015-01-01 04:00:00    NaN    NaN  0.30  16.45    9.2   \n",
            "4           Ahmedabad 2015-01-01 05:00:00    NaN    NaN  0.12  14.90   7.85   \n",
            "...               ...                 ...    ...    ...   ...    ...    ...   \n",
            "707870  Visakhapatnam 2020-06-30 20:00:00   9.50  36.00  2.75  25.57  15.85   \n",
            "707871  Visakhapatnam 2020-06-30 21:00:00  17.25  49.25  3.62  33.20  20.62   \n",
            "707872  Visakhapatnam 2020-06-30 22:00:00  36.00  71.00  2.20  30.80   18.2   \n",
            "707873  Visakhapatnam 2020-06-30 23:00:00  15.75  63.00  1.02  28.90   16.0   \n",
            "707874  Visakhapatnam 2020-07-01 00:00:00  15.00  66.00  0.40  26.85  14.05   \n",
            "\n",
            "          CO     SO2      O3 Benzene  Month  Year  Hour Minute   \n",
            "0        1.0  122.07     NaN     NaN      1  2015     1    NaN  \\\n",
            "1       0.02   85.90     NaN     NaN      1  2015     2    NaN   \n",
            "2       0.08   52.83     NaN     NaN      1  2015     3    NaN   \n",
            "3        0.3   39.53  153.58     NaN      1  2015     4    NaN   \n",
            "4       0.12   32.63     NaN     NaN      1  2015     5    NaN   \n",
            "...      ...     ...     ...     ...    ...   ...   ...    ...   \n",
            "707870  0.62     NaN   27.75     NaN      6  2020    20    NaN   \n",
            "707871  0.76    2.02   25.58     NaN      6  2020    21    NaN   \n",
            "707872  0.58    1.77   26.15     NaN      6  2020    22    NaN   \n",
            "707873  0.49    0.75   15.82     NaN      6  2020    23    NaN   \n",
            "707874  0.59    2.10   17.05     NaN      7  2020  <NA>    NaN   \n",
            "\n",
            "        valid_pollutants  \n",
            "0                      5  \n",
            "1                      5  \n",
            "2                      5  \n",
            "3                      6  \n",
            "4                      5  \n",
            "...                  ...  \n",
            "707870                 7  \n",
            "707871                 8  \n",
            "707872                 8  \n",
            "707873                 8  \n",
            "707874                 8  \n",
            "\n",
            "[609308 rows x 16 columns]\n"
          ]
        }
      ],
      "source": [
        "pollutants = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
        "\n",
        "\n",
        "# Function to clean data for each city\n",
        "def clean_city_data(city_df, threshold=4):  # Change threshold based on desired pollutant count\n",
        "    # Calculate the total number of rows for this city\n",
        "    total_rows = city_df.shape[0]\n",
        "    \n",
        "    # Replace zero values with NaN for easier filtering\n",
        "    city_df.replace(0, pd.NA, inplace=True)\n",
        "    \n",
        "    # Count number of non-NaN pollutant values per row\n",
        "    city_df['valid_pollutants'] = city_df[pollutants].notna().sum(axis=1)\n",
        "    \n",
        "    # Filter rows with too few valid pollutant values (e.g., less than 'threshold')\n",
        "    city_cleaned_df = city_df[city_df['valid_pollutants'] >= threshold]\n",
        "    \n",
        "    # Ensure no more than half of the rows are removed\n",
        "    max_removal = total_rows // 2  # Half the total number of rows\n",
        "    removed_rows = total_rows - city_cleaned_df.shape[0]\n",
        "    \n",
        "    # If too many rows are removed, adjust by selecting rows randomly\n",
        "    if removed_rows > max_removal:\n",
        "        print(f\"Too many rows removed for {city_df['City'].iloc[0]}. Retaining maximum allowed rows.\")\n",
        "        city_cleaned_df = city_df.sample(frac=0.5)  # Retain only 50% of the rows\n",
        "    \n",
        "    return city_cleaned_df\n",
        "\n",
        "# 2. Loop through each city and clean its data\n",
        "cleaned_dataframes = []\n",
        "\n",
        "for city in cities:\n",
        "    city_df = df[df['City'] == city].copy()  # Filter rows for the current city\n",
        "    cleaned_city_df = clean_city_data(city_df)  # Clean the data for this city\n",
        "    cleaned_dataframes.append(cleaned_city_df)  # Store the cleaned data\n",
        "\n",
        "# Concatenate the cleaned data back into a single DataFrame\n",
        "df_cleaned = pd.concat(cleaned_dataframes)\n",
        "\n",
        "# View the final cleaned DataFrame\n",
        "print(df_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 609308 entries, 0 to 707874\n",
            "Data columns (total 16 columns):\n",
            " #   Column            Non-Null Count   Dtype         \n",
            "---  ------            --------------   -----         \n",
            " 0   City              609308 non-null  object        \n",
            " 1   Datetime          609308 non-null  datetime64[ns]\n",
            " 2   PM2.5             551735 non-null  float64       \n",
            " 3   PM10              400444 non-null  float64       \n",
            " 4   NO                582173 non-null  float64       \n",
            " 5   NO2               581185 non-null  float64       \n",
            " 6   NOx               545230 non-null  object        \n",
            " 7   CO                544214 non-null  object        \n",
            " 8   SO2               567350 non-null  float64       \n",
            " 9   O3                567904 non-null  float64       \n",
            " 10  Benzene           414722 non-null  object        \n",
            " 11  Month             609308 non-null  int32         \n",
            " 12  Year              609308 non-null  int32         \n",
            " 13  Hour              584006 non-null  object        \n",
            " 14  Minute            0 non-null       object        \n",
            " 15  valid_pollutants  609308 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(6), int32(2), int64(1), object(6)\n",
            "memory usage: 74.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df_cleaned.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e_bpMTeFR_t",
        "outputId": "7a040aa6-952b-481b-a989-6fbbe0e37ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        City            Datetime      PM2.5        PM10    NO    NO2    NOx   \n",
            "0  Ahmedabad 2015-01-01 01:00:00  68.204801  119.589988  1.00  40.01  36.37  \\\n",
            "1  Ahmedabad 2015-01-01 02:00:00  68.204801  119.589988  0.02  27.75  19.73   \n",
            "2  Ahmedabad 2015-01-01 03:00:00  68.204801  119.589988  0.08  19.32  11.08   \n",
            "3  Ahmedabad 2015-01-01 04:00:00  68.204801  119.589988  0.30  16.45   9.20   \n",
            "4  Ahmedabad 2015-01-01 05:00:00  68.204801  119.589988  0.12  14.90   7.85   \n",
            "\n",
            "     CO     SO2          O3   Benzene  Month  Year Hour Minute   \n",
            "0  1.00  122.07   34.878862  3.984604      1  2015    1    NaN  \\\n",
            "1  0.02   85.90   34.878862  3.984604      1  2015    2    NaN   \n",
            "2  0.08   52.83   34.878862  3.984604      1  2015    3    NaN   \n",
            "3  0.30   39.53  153.580000  3.984604      1  2015    4    NaN   \n",
            "4  0.12   32.63   34.878862  3.984604      1  2015    5    NaN   \n",
            "\n",
            "   valid_pollutants  \n",
            "0                 5  \n",
            "1                 5  \n",
            "2                 5  \n",
            "3                 6  \n",
            "4                 5  \n"
          ]
        }
      ],
      "source": [
        "# List of columns to fill NaN values\n",
        "columns_to_fill = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
        "\n",
        "# Fill NaN values for the specified columns without affecting the Date column\n",
        "df_cleaned[columns_to_fill] = df_cleaned[columns_to_fill].fillna(df_cleaned[columns_to_fill].mean())\n",
        "\n",
        "# Ensure the Date column remains intact\n",
        "print(df_cleaned.head())  # Check if Date column is still present\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "drffoNHqFT1F"
      },
      "outputs": [],
      "source": [
        "# Define features\n",
        "time_features = ['Month', 'Year', 'Hour', 'Minute']\n",
        "air_quality_features = ['PM2.5','PM10', 'NO', 'NO2', 'NOx', 'CO', 'SO2', 'O3', 'Benzene']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Km8Gv3BfFVlc"
      },
      "outputs": [],
      "source": [
        "# Prepare the preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', MinMaxScaler(), time_features + air_quality_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), ['City']) # Change 'sparse' to 'sparse_output'\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PpzzwxCrFYYN"
      },
      "outputs": [],
      "source": [
        "# Fit the preprocessor and transform the data\n",
        "X = preprocessor.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dNAVfx4QFZ3q"
      },
      "outputs": [],
      "source": [
        "# Prepare sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:(i + seq_length)])\n",
        "        y.append(data[i + seq_length, -len(air_quality_features):])  # Only predict air quality features\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 24  # Use 24 hours of data to predict the next hour\n",
        "X_seq, y_seq = create_sequences(X, seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kGgKtZn4Fne8"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "za68nfKlFpjW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sunha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build the LSTM model\n",
        "input_shape = X_train.shape[1:]\n",
        "model = Sequential([\n",
        "    LSTM(64, activation='relu', input_shape=input_shape, return_sequences=True),\n",
        "    LSTM(32, activation='relu'),\n",
        "    Dense(len(air_quality_features))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "h2qQIdCgFtoU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 13ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m3982/3982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 14ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m1260/3982\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: nan"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "\n",
        "\n",
        "# Early stopping callback to stop training when validation loss stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train, y_train, \n",
        "          epochs=50, \n",
        "          batch_size=128, \n",
        "          validation_split=0.1, \n",
        "          verbose=1, \n",
        "          callbacks=[early_stopping])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KelF8Qh2HqMU"
      },
      "outputs": [],
      "source": [
        "# Save the model in SavedModel format (this is the default format)\n",
        "model.save('city_hr_model1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVo3DZ2PIJd6"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSQFSL_-ISv4"
      },
      "outputs": [],
      "source": [
        "def predict_future(model, preprocessor, last_sequence, station_id, future_datetime, num_hours=24):\n",
        "    # Generate a range of datetimes, starting from the input datetime\n",
        "    future_datetimes = [future_datetime + timedelta(hours=i) for i in range(num_hours)]\n",
        "\n",
        "    # Prepare the input sequence\n",
        "    last_sequence_df = pd.DataFrame(last_sequence, columns=time_features + air_quality_features)\n",
        "    last_sequence_df['City'] = station_id\n",
        "\n",
        "    # Transform the last sequence\n",
        "    last_sequence_transformed = preprocessor.transform(last_sequence_df)\n",
        "\n",
        "    # Initialize the sequence for prediction\n",
        "    current_sequence = last_sequence_transformed[-seq_length:]\n",
        "\n",
        "    future_predictions = []\n",
        "\n",
        "    for future_dt in future_datetimes:\n",
        "        # Prepare the input for the next time step\n",
        "        next_input = np.zeros((1, seq_length, current_sequence.shape[1]))\n",
        "        next_input[0, :-1, :] = current_sequence[1:]\n",
        "\n",
        "        # Update time features for the next step\n",
        "        time_features_next = [future_dt.month, future_dt.year, future_dt.hour, future_dt.minute]\n",
        "        next_input[0, -1, :len(time_features)] = preprocessor.named_transformers_['num'].transform([time_features_next + [0]*len(air_quality_features)])[0, :len(time_features)]\n",
        "\n",
        "        # Keep the StationId encoding the same\n",
        "        station_id_cols = preprocessor.named_transformers_['cat'].transform([[station_id]])\n",
        "        next_input[0, -1, len(time_features) + len(air_quality_features):] = station_id_cols\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(next_input)\n",
        "\n",
        "        # Store the prediction\n",
        "        future_predictions.append(prediction[0])\n",
        "\n",
        "        # Update the sequence for the next iteration\n",
        "        current_sequence = next_input[0]\n",
        "        current_sequence[-1, len(time_features):-len(station_id_cols[0])] = prediction[0]\n",
        "\n",
        "    # Convert predictions to original scale\n",
        "    future_predictions = np.array(future_predictions)\n",
        "    future_predictions_inv = preprocessor.named_transformers_['num'].inverse_transform(\n",
        "        np.column_stack((np.zeros((len(future_predictions), len(time_features))), future_predictions)))[:, -len(air_quality_features):]\n",
        "\n",
        "    return future_predictions_inv, future_datetimes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfa_GniNIWY8"
      },
      "outputs": [],
      "source": [
        "# Get user input\n",
        "'''\n",
        "station_id = input(\"Enter StationId: \")\n",
        "future_date = input(\"Enter future Date (YYYY-MM-DD): \")\n",
        "future_time = input(\"Enter future Time (HH:MM:SS): \")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsL8p_I0JcPn"
      },
      "outputs": [],
      "source": [
        "station_id = 'Ahmedabad'\n",
        "future_date = '2024-09-27'\n",
        "future_time = '12:00:00'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGKB_hC6IX5h"
      },
      "outputs": [],
      "source": [
        "future_datetime = datetime.strptime(f\"{future_date} {future_time}\", \"%Y-%m-%d %H:%M:%S\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb2SnmusIaSk"
      },
      "outputs": [],
      "source": [
        "last_sequence = df[df['StationId'] == station_id].sort_values('Datetime').iloc[-seq_length:]\n",
        "last_sequence = last_sequence[time_features + air_quality_features].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN5jr5YWIbmi"
      },
      "outputs": [],
      "source": [
        "future_predictions, prediction_datetimes = predict_future(model, preprocessor, last_sequence, station_id, future_datetime)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1uCvcfNIc1e"
      },
      "outputs": [],
      "source": [
        "future_df = pd.DataFrame(future_predictions, columns=air_quality_features, index=prediction_datetimes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "porGgiH_JBRa"
      },
      "outputs": [],
      "source": [
        "print(future_df)\n",
        "\n",
        "# Print the prediction for the specific datetime entered by the user\n",
        "specific_prediction = future_df.loc[future_datetime]\n",
        "print(f\"\\nPrediction for {future_datetime} at station {station_id}:\")\n",
        "for feature, value in specific_prediction.items():\n",
        "    print(f\"{feature}: {value:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
